<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- saved from url=(0031)http://cfcs.pku.edu.cn/baoquan/ -->
<html><head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JN0ZL4NGD9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-JN0ZL4NGD9');
  </script>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="generator" content="HTML Tidy for Linux (vers 25 March 2009), see www.w3.org">
  
  <meta name="author" content="Baoquan Chen">
  <meta name="description" content="Baoquan&#39;s Homepage">
  <meta name="robots" content="index, follow, noarchive">
  <meta name="googlebot" content="noarchive">
  <style type="text/css">
A.applink:hover {border: 2px dotted #DCE6F4;padding:2px;background-color:#ffff00;color:green;text-decoration:none}
        A.applink       {border: 2px dotted #DCE6F4;padding:2px;color:#2F5BFF;background:transparent;text-decoration:none}
        A.info          {color:#2F5BFF;background:transparent;text-decoration:none}
        A.info:hover    {color:green;background:transparent;text-decoration:underline}
  </style>

  <title>Baoquan Chen (陈宝权), Peking University</title>
    <script type="text/javascript" async="" src="./figure/ga.js.下载"></script><script type="text/javascript" async="" src="./figure/ga.js(1).下载"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-32399596-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>

<body background="./figure/welcomebg.gif" link="#253FB2">

  <table align="center" width="1024" summary="">
    <tbody><tr>
      <td><img src="./figure/Baoquan_portrait.jpg" width="300" alt="Baoquan&#39;s portrait"><br>
      </td>

      <td>
        <h1>Baoquan Chen (陈宝权) <a href="The Chop.html"><img src="./figure/chop_cbq_s.jpg" width="40" alt=""></a></h1>

<h3 style="font:&#39;Times New Roman&#39;, Times, serif">Associate Dean of <a href="https://www.cis.pku.edu.cn/">the School of Artificial Intelligence</a>, <a href="http://www.pku.edu.cn/">Peking University</a>.</h3>

<!-- <h3 style="font:&#39;Times New Roman&#39;, Times, serif">北京大学智能学院，副院长</h3> -->

<p><br>
  <font size="-1">
    Past positions: <br>
    Executive director of the <a href="https://cfcs.pku.edu.cn/">Center on Frontiers of Computing Studies</a>, <a href="https://www.pku.edu.cn/">PKU</a><br>
    Founding Director of the <a href="http://irc.cs.sdu.edu.cn/">Interdisciplinary Research Center</a>, <a href="http://www.sdu.edu.cn/">SDU</a><br>
    Founding Director of the <a href="http://english.siat.cas.cn/">Visual Computing Research Center</a>, <a href="http://english.siat.cas.cn/">SIAT</a><br>
    Deputy Director of the <a href="http://english.siat.cas.cn/">Institute of Advanced Computing and Digital Engineering (IACDE)</a>
  </font>
</p>

<!-- <p><br>
<font size="-1">Formerly Founding Director of the <a href="http://irc.cs.sdu.edu.cn/">Interdisciplinary Research Center</a>，<a href="http://www.sdu.edu.cn/">SDU</a><br>
Formerly Founding Director of the <a href="http://english.siat.cas.cn/">Visual Computing Research Center</a>，<a href="http://english.siat.cas.cn/">SIAT</a><br>
Formerly Deputy Director of the <a href="http://szs.siat.ac.cn/">Institute of Advanced Computing and Digital Engineering (IACDE)</a></font></p> -->

<p>Email: baoquan At pku.edu.cn <a href="http://weibo.com/baoquanchen" target="blank_"><img height="32" src="./figure/sina-weibo.png"></a>: <a href="http://weibo.com/baoquanchen" target="blank_">http://weibo.com/baoquanchen</a><br>
Address: Rm 2216, Li Ke Building #2, Peking University, 5 Yiheyuan Road, Haidian District, Beijing 100871, P.R. China</p>

<p><b>Open positions available (researchers, PostDocs, graduate students, interns). Contact me for details.</b></p>

<p><b>Research Interests</b><br>
<u>General Interests</u>: Computer Graphics and Visualization<br>
<u>Specific Interests</u>: Large Environment Acquisition, Accelerated Rendering, Antialiasing, Volume Visualization<br>
<u>Applications</u>: Scientific &amp; Biomedical Visualization, Digital Architecture Design, Art and Entertainment</p>

<p><b>Portrait</b><br>
<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-08/20210807171127844317.jpg">Full</a>,&nbsp;<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-08/20210807171132313456.jpg">face</a>,&nbsp;<a href="figure/face2.jpg">face2</a></p>


<!--h3 style="font:&#39;Times New Roman&#39;, Times, serif">Dean of the <a href="http://www.cs.sdu.edu.cn/default.do">School of Computer Science and Technology</a> and <a href="http://www.cs.sdu.edu.cn/default.do"></a><a href="http://www.sc.sdu.edu.cn/default.do">School of Software Engineering</a> , <a href="http://www.sdu.edu.cn/">Shandong University</a></h3>
        <p><font size="-1"><br>
		Founding Director of the <a href="http://irc.cs.sdu.edu.cn/">Interdisciplinary Research Center</a>，<a href="http://www.sdu.edu.cn/">SDU</a><br>
		
        Formerly Founding Director of the <a href="http://vcc.siat.ac.cn/">Visual
        Computing Research Center</a>，<a href="http://english.siat.cas.cn/">SIAT</a><br>
          Formerly Deputy Director of the <a href="http://szs.siat.ac.cn/">Institute of Advanced Computing
        and Digital Engineering (IACDE)</a></font></p>
<p></p>
        <p>Email: baoquan At sdu.edu.cn
		<a href="http://weibo.com/baoquanchen" target="blank_"><img src="images/sina-weibo.png" height="32"></a>: <a href="http://weibo.com/baoquanchen" target="blank_">http://weibo.com/baoquanchen</a>
		<br>
        Address: No.1500, Shunhua Road, Jinan, Shandong Province, P.R. China </p>
        <p><b>Open positions available (researchers, PostDocs, graduate students, interns). Contact me for details.</b></p>

		<p><b>Looking for PostDocs! This is a joint position between <a href="http://www.cs.tau.ac.il/~dcor/index.html">Daniel Cohen-Or</a> and me, under a China-Israel joint grant. To apply, please email us both together.</b></p>
		
		
        <p><b>Research Interests</b><br>
        <u>General Interests</u>: Computer Graphics and
        Visualization<br>
        <u>Specific Interests</u>: Large Environment Acquisition,
        Accelerated Rendering, Antialiasing, Volume
        Visualization<br>
        <u>Applications</u>: Scientific &amp; Biomedical
        Visualization, Digital Architecture Design, Art and
        Entertainment<br></p-->

      </td>
    </tr>
  </tbody></table>

  <table align="center" width="1024" border="2" summary="">
    <tbody><tr>
      <td><i><font size="+2" color="#5F3F0E">News</font></i></td>

      <td>
        <ul>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">3.25: talk by </span><a href="https://jytime.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Jianyuan Wang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Visual Geometry Group (VGG), University of Oxford,&nbsp;<i>VGGT: Visual Geometry Grounded Transformer
          </i>.</span></li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">3.14: talk by Prof. </span><a href="https://yanchaoyang.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yanchao Yang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Electrical and Computer Engineering and the Institute of Data Science, the University of Hong Kong,&nbsp;<i>InfoBodied AI: Learning Mutual Information for Embodied AI
          </i>.</span></li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">2.28: talk by Prof. </span><a href="https://yoyo000.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yao Yao</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from School of Intelligence Science and Technology, Nanjing University,&nbsp;<i>Creating a Realistic 3D World
          </i>.</span></li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">1.10: talk by Dr. </span><a href="https://qianqianwang68.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Qianqian Wang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from UC Berkeley,&nbsp;<i>Perceiving and Understanding the Dynamic 3D World</i>.</span></li>
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">12.20: talk by </span><a href="https://zhufyaxel.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Fengyuan Zhu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from University of Toronto,&nbsp;<i>Overcoming XR Barriers: Integrating Devices, Refining Inputs, and Exploring Future Prospects</i>.</span></li> -->
          <!-- <li><sp~an style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">12.13: talk by </span><a href="https://alisomia.github.io/website/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Ting Lin</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from School of Mathematical Sciences, Peking University,&nbsp;<i>Universal Approximation Properties of Deep Neural Networks: A control theory perspective</i>.</span></li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">11.29: talk by Prof. </span><a href="https://yuexinma.me/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yuexin Ma</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ShanghaiTech University,&nbsp;<i>Perception, Cognition, and Action in Embodied AI</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">11.22: talk by Prof. </span><a href="https://rachelcmy.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Mengyu Chu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Peking University,&nbsp;<i>3D和动态内容生成的探索及应用——Mini3DV参会报告</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">11.1: talk by Dr. </span><a href="https://zhengqili.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Zhengqi Li</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Google DeepMind,&nbsp;<i>Modeling Motion in the Wild</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.17: talk by Prof. </span><a href="https://ge.in.tum.de/about/n-thuerey/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Nils Thuerey</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Technical University of Munich,&nbsp;<i>Diffusion Flow Matching and ProbabilisticLearned Solvers</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.11: talk by </span><a href="https://scholar.google.com/citations?hl=zh-CN&user=u4olrOcAAAAJ" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Xiaoliang Dai</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Meta GenAI,&nbsp;<i>Foundation Models for Image and Video Generation</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.27: talk by </span><a href="https://aubrey-ao.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Tenglong Ao</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Peking University,&nbsp;<i>Interactive Video Model</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.20: talk by Dr. </span><a href="https://www.xu-lan.com/index.html" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Lan Xu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ShanghaiTech University,&nbsp;<i>Gen-AI and Neural Digital Humans</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">8.28: talk by Dr. </span><a href="https://huangjh-pub.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Jiahui Huang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from NVIDIA Toronto AI Lab,&nbsp;<i>3D Reconstruction and Generation with Sparse Voxel Hierarchies: From Infrastructure to Applications</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">8.20: talk by </span><a href="https://www.cs.toronto.edu/~linghuan/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Huan Ling</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Toronto,&nbsp;<i>Go beyond pixels: From Video Diffusion Models to 4D Dynamic Content Creation</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.18: talk by Dr. </span><a href="https://www.sci.utah.edu/~shachar/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Shachar Fleishman</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Utah,&nbsp;<i>MeshCNN: A Network with An Edge</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.18: talk by Prof. </span><a href="https://www.cs.sfu.ca/~haoz/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Hao (Richard) Zhang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Simon Fraser University,&nbsp;<i>Neural Fields and Language Models for 3D Generative AI</i>.</span> -->
          </li>
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">6.3: talk by Dr. </span><a href="https://www.dgp.toronto.edu/~eitan/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Eitan Grinspun</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Toronto,&nbsp;<i>Adventures in Discretization of Mechanical Systems</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">12.25: talk by </span><a href="https://justimyhxu.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yinghao Xu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Stanford University,&nbsp;<i>Large reconstruction model for 3D reconstruction and generation</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">11.27: talk by </span><a href="https://lingjie0206.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Lingjie Liu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Pennsylvania,&nbsp;<i>From 3D Reconstruction to 3D Generation</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">11.10: talk by </span><a href="https://zhenxuan00.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Chongxuan Li</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Renmin University of China,&nbsp;<i>Diffusion Model and Visual Content Generation</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.13: talk by </span><a href="https://yangzzzy.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yin Yang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Utah,&nbsp;<i>Linearly and Nonlienarly Reduced Models for Fast Solid Simulation</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.25: talk by </span><a href="https://kuiwuchn.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Kui Wu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tencent America,&nbsp;<i>A general sag-free initialization for deformable simulations</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.5: talk by Prof. </span><a href="https://www.cs.sfu.ca/~haoz/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Hao (Richard) Zhang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Simon Fraser University,&nbsp;<i>An Evolution of Learning Neural Implicit Representations for 3D Shapes</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">8.22: talk by </span><a href="https://www.yf.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Fisher Yu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zürich,&nbsp;<i>Scaling Up 4D Scene Understanding with Less Hassle</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.31: talk by Prof. </span><a href="https://www.cse.wustl.edu/~taoju/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Tao Ju</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Washington University,&nbsp;<i>Interactive Modeling with Implicit Functions</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.27: talk by </span><a href="https://vlg.inf.ethz.ch" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Siyu Tang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zürich,&nbsp;<i>Reconstruction and synthesis of 3D humans in 3D scenes</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.25: talk by </span><a href="https://gaoxifeng.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Xifeng Gao</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tencent,&nbsp;<i>Robust Low-Poly Meshing</i>.</span>
          </li> -->

          <!--
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.19: talk by </span><a href="https://cqf.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Qifeng Chen</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from HKUST,&nbsp;<i>Towards Photorealistic Video and 3D Synthesis with Foundation Models</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.12: talk by </span><a href="https://xiuyuliang.cn/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yuliang Xiu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Max Planck Institute for Intelligent Systems,&nbsp;<i>Towards large-scale human digitization from in-the-wild pixels, Explicit or Implicit?</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.28: talk by </span><a href="https://peterchencyc.com/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Peter Yichen Chen</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from MIT CSAIL,&nbsp;<i>Fast and Accurate PDE Solvers via Neural Fields</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.25: talk by </span><a href="https://www.cs.toronto.edu/~jungao/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Jun Gao</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Toronto,&nbsp;<i>Machine Learning for 3D Content Creation</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.14: talk by </span><a href="https://people.inf.ethz.ch/~linyang/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Lingchen Yang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zurich,&nbsp;<i>Implicit Neural Representations for Actuated Soft Bodies and High-fidelity Hair</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.14: talk by </span><a href="https://www.cs.huji.ac.il/~danix/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Prof. Daniel Lischinski</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the Hebrew University of Jerusalem,&nbsp;<i>Controllable Generative Models</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.14: talk by </span><a href="https://danielcohenor.com/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Prof. Daniel Cohen-Or</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the Tel-Aviv University,&nbsp;<i>Textual Inversion</i>.</span>
          </li>

			 <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.7: talk by </span><a href="https://www.cse.cuhk.edu.hk/~qdou/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Qi Dou</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the Chinese University of Hong Kong,&nbsp;<i>From Videos to 4D Worlds and Beyond</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.7: talk by </span><a href="https://people.eecs.berkeley.edu/~kanazawa/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Angjoo Kanazawa</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of California, Berkeley,&nbsp;<i>Decoupling Human and Camera Motion from Videos in the Wild</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">3.31: talk by </span><a href="https://people.iiis.tsinghua.edu.cn/~taodu/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Tao Du</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tsinghua University,&nbsp;<i>Computational Design of Physical Systems with Solid-Fluid Coupling</i>.</span>
          </li> -->
			
<!--
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">12.3: talk by &nbsp;</span><a href="https://www.cs.utexas.edu/~grauman/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Kristen Grauman</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from University of Texas at Austin,&nbsp;<i>Sounds and space for audio-visual learning</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.21: talk by &nbsp;</span><a href="http://www.cs.toronto.edu/~jungao/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Gao Jun</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from University of Toronto,&nbsp;<i>Towards Generative Modeling of 3D Objects Learned from Images</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.7: talk by Dr.&nbsp;</span><a href="https://cseweb.ucsd.edu/~zex014/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Zexiang Xu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Adobe Research,&nbsp;<i>Neural Scene Representations and Applications</i>.</span>
          </li>
			
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.23: talk by Dr.&nbsp;</span><a href="https://www.cs.cornell.edu/~hadarelor/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Hadar Averbuch-Elor</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Cornell Tech,&nbsp;<i>Deep into 3DV: Pushing the Boundaries of 3D Vision</i>.</span>
          </li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">8.26: talk by&nbsp;</span><a href="https://www.purvigoel.com//" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Purvi Goel</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Stanford University,&nbsp;<i>Unified Many Worlds Browsing of Arbitrary Physics-Based Animations</i>.</span>
</li>
-->
<!--
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.22: talk by Dr.&nbsp;</span><a href="http://dannykaufman.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Danny Kaufman</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Adobe Research,&nbsp;<i>Incremental Potential Contact: Simulating Dynamics with Correctness and Interactivity</i>.</span>
</li>
-->
<!--
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.15: talk by Dr. </span><a href="http://www.connellybarnes.com/work/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Connelly Barnes</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Adobe and </span><a href="https://www.cs.princeton.edu/~yutingy/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yuting Yang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Princeton University,&nbsp;<i>Aδ: Autodiff for Discontinuous Programs – Applied to Shaders</i>.</span>
</li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.1: talk by&nbsp;</span><a href="https://sites.google.com/site/jsmerel/home/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Josh Merel</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Reality Labs,&nbsp;<i>Neural motor skills for simulated and robotic agents</i>.</span>
</li>
-->
                      <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">6.3: talk by&nbsp;</span><a href="https://zhengqili.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Zhengqi Li</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Google Research,&nbsp;<i>Beyond Novel View</i>.</span>
</li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.27: talk by&nbsp;</span><a href="http://crl.ethz.ch/people/coros/index.html" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Stelian Coros</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zurich,&nbsp;<i>Physics-based modeling and the quest for intelligent robots</i>.</span>
</li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.13: talk by&nbsp;</span><a href="https://yotamnitzan.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yotam Nitzan</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tel-Aviv Univeristy,&nbsp;<i>MyStyle: A Personalized Generative Prior</i>.</span>
</li> -->
                      <li><a href="http://vcl.pku.edu.cn/seminars">More</a>
</li>
                   
        </ul>
      </td>
    </tr>

    <tr>
      <td><i><font size="+2" color="#5F3F0E">Research</font></i></td>

      <td>
        <table summary="">
          <tbody><tr>
            <td>
             
<p>
ORCID：0000-0003-4702-036X<br>
<a href="Projects&Publications.html"><font size="+2" color="#5F3F0E">Full list of publications</font></a>
      </p><p>Recent publications</p>

<ul>
  <li>Qiyu Dai*, Xingyu Ni*, Qianfan Shen, Wenzheng Chen, Baoquan Chen, Mengyu Chu. <strong>RainyGS: Efficient Rain Synthesis with Physically-Based Gaussian Splatting.</strong> CVPR&nbsp;2025.</li>
  <li>Yuzheng Liu*, Siyan Dong*, Shuzhe Wang, Yingda Yin, Yanchao Yang, Qingnan Fan, Baoquan Chen. <strong>SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos.</strong> CVPR&nbsp;2025.</li>
  <li>Liangwang Ruan, Bin Wang, Tiantian Liu, Baoquan Chen. <strong>MiNNIE: a Mixed Multigrid Method for Real-time Simulation of Nonlinear Near-Incompressible Elastics.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2024.</li>
  <li>Xuwen Chen, Cheng Yu, Xingyu Ni, Mengyu Chu, Bin Wang, Baoquan Chen. <strong>A Time-Dependent Inclusion-Based Method for Continuous Collision Detection between Parametric Surfaces.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2024.</li>
  <li>Baoquan Chen, Zhouchen Lin, Peng Xi, Yebin Liu, Xiaodian Chen. <strong>Embodied computational imaging: a new paradigm for observing and analyzing spatiotemporally ultrasensitive phenomena at multiple scales.</strong> Science China Information Sciences&nbsp;2024.</li>
  <!-- <li>Xingyu Ni, Xuwen Chen, Bin Wang, Baoquan Chen. <strong>Simulating Thin Shells by Bicubic Hermite Elements.</strong> Computer-Aided Design&nbsp;2024.</li> -->
  <li>Xingyu Ni, Ruicheng Wang, Bin Wang, Baoquan Chen. <strong>An Induce-on-Boundary Magnetostatic Solver for Grid-Based Ferrofluids.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2024.</li>
  <li>Ningxiao Tao, Liangwang Ruan, Yitong Deng, Bo Zhu, Bin Wang, Baoquan Chen. <strong>A Vortex Particle-on-Mesh Method for Soap Film Simulation.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2024.</li>
  <li>Zeyi Zhang, Tenglong Ao, Yuyao Zhang, Qingzhe Gao, Chuan Lin, Baoquan Chen, Libin Liu. <strong>Semantic Gesticulator: Semantics-Aware Co-Speech Gesture Synthesis.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2024.</li>
  <li>Heyuan Yao, Zhenhua Song, Yuyang Zhou, Tenglong Ao, Baoquan Chen, Libin Liu. <strong>Moconvq: Unified physics-based motion control via scalable discrete representations.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2024.</li>
  <li>Yuanxing Duan, Fangyin Wei, Qiyu Dai, Yuhang He, Wenzheng Chen, Baoquan Chen. <strong>4D-Rotor Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2024.</li>
  <li>Yujie Wang, Xuelin Chen, Baoquan Chen. <strong>SinGRAV: Learning a Generative Radiance Volume from a Single Natural Scene.</strong> Journal of Computer Science and Technology&nbsp;2024.</li>
  <li>Yingda Yin, Yuzheng Liu, Yang Xiao, Daniel Cohen-Or, Jingwei Huang, Baoquan Chen. <strong>SAI3D: Segment Any Instance in 3D Scenes.</strong> CVPR&nbsp;2024.</li>
  <li>Hongda Jiang, Xi Wang, Marc Christie, Libin Liu, Baoquan Chen. <strong>Cinematographic Camera Diffusion Model.</strong> Eurographics&nbsp;2024.</li>
  <li>Yimo Yan, Chao Song, Zaiyi Shen, Yuechen Zhu, Xingyu Ni, Bin Wang, Michael G. Christiansen, Stavros Stavrakis, Juho S. Lintuvuori, Baoquan Chen, Andrew deMello, Simone Schuerle. <strong>Programming structural and magnetic anisotropy for tailored interaction and control of soft microrobots.</strong> Communications Engineering (Nature Communications)&nbsp;2024.</li>
  <li>Weiyu Li, Xuelin Chen, Peizhuo Li, Olga Sorkine-Hornung, Baoquan Chen. <strong>Example-based Motion Synthesis via Generative Motion Matching.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2023.</li>
  <li>Yingda Yin, Yang Wang, He Wang, Baoquan Chen. <strong>A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation.</strong> ICLR 2023.</li>
	<li>Tenglong Ao, Qingzhe Gao, Yuke Lou, Baoquan Chen, Libin Liu.&nbsp;<strong>Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2022 (<strong>Best Paper Award</strong>).</span></li>
	<li>Heyuan Yao, Zhenhua Song, Baoquan Chen, Libin Liu.&nbsp;<strong>ControlVAE: Model-Based Learning of Generative Controllers for Physics-Based Characters</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2022.</span></li>
	<li>Jingrui Xing, Liangwang Ruan, Bin Wang, Bo Zhu, Baoquan Chen.&nbsp;<strong>Position-based Surface Tension Flow</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2022.</span></li>
	<li>Xuwen Chen, Xingyu Ni, Bo Zhu, Bin Wang, Baoquan Chen.&nbsp;<strong>Simulation and optimization of magnetoelastic thin shells</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2022.</span></li>
	<li>Yujie Wang, Praneeth Chakravarthula, Qi Sun, Baoquan Chen.&nbsp;<strong>Joint neural phase retrieval and compression for energy- and computation-efficient holography on the edge</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2022 (<strong>Best Paper Honorable Mention</strong>).</span></li>
<!--
  <li>Yunzhe Liu, Rinon Gal, Amit H. Bermano, Baoquan Chen, Daniel Cohen-Or.&nbsp;<strong>Self-Conditioned GANs for Image Editing</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM SIGGRAPH 2022 Conference Proceedings&nbsp;2022.</span></li>
	<li>Yingda Yin, Yingcheng Cai, He Wang, Baoquan Chen.&nbsp;<strong>FisherMatch: Semi-Supervised Rotation Regression via Entropy-based Filtering</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">CVPR 2022.</span></li>
	<li>Kai Ye, Siyan Dong, Qingnan Fan, He Wang, Li Yi, Fei Xia, Jue Wang, Baoquan Chen.&nbsp;<strong>Multi-Robot Active Mapping via Neural Bipartite Graph Matching</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">CVPR 2022.</span></li>

	<li>Yuchen Sun, Xingyu Ni, Bo Zhu, Bin Wang, Baoquan Chen.&nbsp;<strong>A Material Point Method for Nonlinearly Magnetized Materials</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2021.</span></li>
	<li>Jing Li, Tiantian Liu, Ladislav Kavan, Baoquan Chen.&nbsp;<strong>Interactive Cutting and Tearing in Projective Dynamics with Progressive Cholesky Updates</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2021.</span></li>
	<li>Hongda Jiang, Marc Christie, Xi Wang, Bin Wang, Baoquan Chen.&nbsp;<strong>Camera Keyframing with Style and Control</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia) 2021.</span></li>
	<li>Jian Liu, Shiqing Xin, Xifeng Gao, Kaihang Gao, Kai Xu, Baoquan Chen, Changhe Tu.&nbsp;<strong>Computational Object-Wrapping Rope Nets</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics 2021.</span></li>
	<li>Liangwang Ruan, Jinyuan Liu, Bo Zhu, Shinjiro Sueda, Bin Wang, Baoquan Chen.&nbsp;<strong>Solid-Fluid Interaction with Surface-Tension-Dominant Contact.</strong>&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH) 2021.</span></li>
-->
</ul>
<!-- 
<p>Representative publications</p>

<ul>
	<li>Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan&nbsp;Di, Baoquan Chen.&nbsp;<strong>PointCNN: Convolution on x-transformed points</strong><span style="color: rgb(0, 0, 0); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 13.3333px; white-space: pre-wrap; caret-color: rgb(30, 111, 255);">. </span>Proceedings of&nbsp;Advances in Neural Information Processing Systems (NeurIPS) 2018.</li>
	<li>Lin Lu, Andrei Sharf, Haisen&nbsp;Zhao, Yuan Wei, Qingnan Fan, Xuelin Chen, Yann Savoye,&nbsp;Changhe Tu,&nbsp;Daniel Cohen-Or,&nbsp;Baoquan Chen.&nbsp;<strong>Build-to-last: Strength to weight 3D printed objects</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2014.</span></li>
	<li>Liangliang Nan, Andrei Sharf,&nbsp;Hao Zhang,&nbsp;Daniel Cohen-Or,&nbsp;Baoquan Chen.&nbsp;<strong>Smartboxes for interactive urban reconstruction</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2010.</span></li>
	<li>Hong Zhou, Xiaoru Yuan,&nbsp;Huamin Qu,&nbsp;Weiwei Cui,&nbsp;Baoquan Chen.<strong>&nbsp;Visual clustering in parallel coordinates</strong>.&nbsp;Computer Graphics Forum&nbsp;2008.</li>
</ul> -->

<p>中文文章​</p>

<ul>
  <li>2024年第6期 <a href="https://dl.ccf.org.cn/article/articleDetail.html?type=xhtx_thesis&_ack=1&id=7036931067594752">多尺度具身影像计算专题导言</a></li>
  <li>2024年第6期 <a href="https://dl.ccf.org.cn/article/articleDetail.html?type=xhtx_thesis&_ack=1&id=7036935452526592">多尺度具身影像计算</a></li>
  <li>2022年第12期 <a href="https://dl.ccf.org.cn/article/articleDetail.html?type=xhtx_thesis&_ack=1&id=6262370807842816">计算机图形学将是未来智能的入口</a></li>
	<li>2021年第7期 <a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232736328266.pdf">从数字城市到数字孪生城市</a></li>
	
  <li id="btn_articles">
    <a style="cursor: pointer; text-decoration: underline; color: rgb(37, 63, 178)" onclick="document.getElementById('btn_articles').style.display = 'none'; document.getElementById('collapse_articles').style.display = 'initial'; ">[More]</a>
  </li>

  <dev id="collapse_articles" style="display: none;">
    <li>2020年第7期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232759708333.pdf">面向新冠疫情的数据可视化分析</a></li>
    <li>2019年第6期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232817921426.pdf">赋能机器人——计算机学科的机遇与使命</a></li>
    <li>2016年第8期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232833395547.pdf">大数据时代的城市计算</a></li>
    <li>2016年第8期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232852097605.pdf">大规模城市场景建模与理解</a></li>
    <li>2012年第19期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232952499890.pdf">基于三维视频融合的监控分析系统</a>&nbsp;（《中国公共安全（综合版）》）</li>
    <li>2009年第7期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232712483163.pdf">数字化城市（第一人生）</a></li>
  </dev>
</ul>

<p>以上文章除特别标明，均发表于《中国计算机学会通讯》</p>

<p>新闻报道</p>

<ul>
  <li>2024.5.16: “<a href="https://mp.weixin.qq.com/s/h4UTnaWpqB3qukjFjbCvTA">北大高逼真物理仿真，加持磁性微米级机器人登Nature子刊</a>” （<a href="https://www.nature.com/articles/s44172-023-00145-5">文章链接</a>）</li>
  <li>2024.5.7: “<a href="https://news.pku.edu.cn/xwzh/a7cb6c9dee294d8dad957211be4a6e1a.htm">北京大学陈宝权教授入选ACM“计算机图形学名人堂”</a>”（<a href="https://www.siggraph.org/awards/acm-siggraph-academy/">官方公告</a>）</li>
  <li>
    科技冬奥 【<a href="https://space.bilibili.com/28217340/channel/collectiondetail?sid=812012">合集</a>】
    <ul>
      <li><img height="16" src="./figure/video.png" ><a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-03/20240309122150924435.mp4">交互式观赛技术</a></li>
      <li>2022.3.9: 央视新闻直播间报道北大陈宝权团队科技冬奥项目助力北京冬残奥会：<a href="https://content-static.cctvnews.cctv.com/snow-book/index.html?toc_style_id=feeds_default&amp;share_to=wechat&amp;item_id=7575820793624626086&amp;track_id=24783BE6-23F1-466C-94BF-9BFA5759E497_668505736232">展示给观众接近360度旋转“自由视点”</a></li>
      <li>2021.1.11: “<a href="https://m.bjnews.com.cn/detail/164186887914571.html">北京大学 | 把电影特效带进赛事转播，实现交互式多维度观赛</a>”</li>
	    <li>2021.12.31: <img height="16" src="./figure/video.png" >“<a href="https://www.bilibili.com/video/BV16M4y1F7UT/?share_source=copy_web&vd_source=11203983f1ad5986958c2f35a08a12ce">2022科学跨年之夜</a>”</li>
      <li>2021.11.9: 科技冬奥：<a href="http://www.china.org.cn/business/2021-11/09/content_77861903.htm">“交互式自由视点VR观赛”五棵松体育馆测试</a></li>
	    <li>2021.10.27: 科技日报“<a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjrb/html/2021-10/27/content_523909.htm">冰雪运动，激情飞扬</a>”</li>
      <li>2021.7.19: 科技日报“<a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjrb/html/2021-07/19/content_472010.htm">中国方案提升冬奥会筹办水平</a>”</li>
      <li>2021.6.7: <img height="16" src="./figure/video.png" >北京电视台《冬奥纪实》节目采访陈宝权教授介绍其团队科研成果“<a href="https://m.btime.com/item/218g4ps94j936qsquqmphdq02mg">科技冬奥，交互观赛</a>”</li>
      <li>2021.4.6: 科技日报“<a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjrb/html/2021-04/06/content_465420.htm">场外看冬奥 自由交互技术让你‘身临其境’</a>”</li>
    </ul>
  </li>
  <li id="btn_news">
    <a style="cursor: pointer; text-decoration: underline; color: rgb(37, 63, 178)" onclick="document.getElementById('btn_news').style.display = 'none'; document.getElementById('collapse_news').style.display = 'initial'; ">[More]</a>
  </li>

  <dev id="collapse_news" style="display: none;">
    <li>2021.12.5:&nbsp;当选2021年度<a href="https://mp.weixin.qq.com/s/wKBIuotcQaAtM3k9WjQm2A">中国图象图形学学会会士</a></li>
    <li>2021.9.11: “<a href="https://mp.weixin.qq.com/s/6UYyrhgxZrzOMPmIuG1tEQ">不编程，拖拖鼠标图表自己动起来，新研究获ACM CHI最佳论文荣誉提名</a>”（<a href="http://www.yunhaiwang.net/EuroVis2020/canis/paper.pdf">文章链接</a>）</li>
    <li>2021.7.23: “<a href="https://mp.weixin.qq.com/s/VinRG0nYoUdkE4wA8_cRnQ">AI救援河南洪灾</a>”</li>
    <li>2021.7.15: “<a href="https://mp.weixin.qq.com/s/2_W_vSmayVlsXEbw35gWyw">对话John Hopcroft教授：新国际环境下的高等教育与学术人生</a>”</li>
    <li>2021.5.9: “<a href="https://mp.weixin.qq.com/s/u3eLDjtyGV0aVqEm6KXo6w">模拟水面表面张力，效果自然、真实，北大图灵班研究入选SIGGRAPH</a>”（<a href="https://lwruan.com/publication/waterstrider/">文章链接</a>）</li>
    <li>2020.5.27: “<a href="https://mp.weixin.qq.com/s/uU1-DwHnU4pPMLtQZNQyVQ">北大图灵班本科生带来动画CG福音，「最懂骨骼的卷积网络」</a>”（<a href="https://deepmotionediting.github.io/retargeting">文章链接</a>）</li>
    <li>2020.2.11: “<a href="https://mp.weixin.qq.com/s/GoExay4zzZQcFL1T0f2OfA">面向新冠疫情的数据可视化分析与模拟预测</a>”（<a href="https://arxiv.org/abs/2002.07096">文章链接</a>）</li>
    <li>2016.12.10: <img height="16" src="./figure/video.png">“<a href="https://vcl.pku.edu.cn/misc/20240309.mp4">归去来兮：回到国内做学术的个人体会与观察”</a>（<a href="www.acsic.org">北美计算机华人学者协会</a>访谈）</li>
    <li>2014.10.25 “<a href="https://www.ituring.com.cn/article/127792">陈宝权教授访谈图灵奖获得者Ivan Sutherland</a>”</li>
    <li>2013.4.10: <img height="16" src="./figure/video.png" >中央电视台《走进科学》专题报道陈宝权教授及其团队科研成果—“<a href="http://tv.cctv.com/2013/04/09/VIDE1365519779747781.shtml">把城市搬进电脑</a>”</li>
    <li>2010.4.28: 晶报新闻“<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-10/20211020150616225114.pdf">用‘阿凡达’技术‘重建’深圳</a>”</li>
  </dev>
</ul>

<p>Funding provided by: NSF, ARL, ONR, Microsoft (~2008), NSFC, MOST, Nvidia, etc.</p>

              <!--  <ul>
                <li><a href="research/projects_publications/index.htm"><font size="+1" color="#5F3F0E">Projects &amp;
                Publications</font></a></li>
      
</ul>      -->
 
<p></p>        
            </td>

            <td valign="bottom">&nbsp;</td>

            <td valign="bottom">&nbsp;</td>

            <td valign="bottom">&nbsp;</td>
          </tr>
        </tbody></table>
      </td>
    </tr>

    <tr>
      <td><i><font size="+2" color="#5F3F0E">Service</font></i></td>

      <td>
                      <p><font size="+0">Program committee member unless otherwise noted (not up to date):</font></p>

<ul>
	<li>SIGGRAPH (<a href="https://history.siggraph.org/conference/siggraph-2017-44th-annual-conference-on-computer-graphics-and-interactive-techniques/">2017</a>), SIGGRAPH Asia (<a href="http://sa2013.siggraph.org/">2013</a>,&nbsp;<a href="http://sa2014.siggraph.org/en/">2014</a>)</li>
	<li><a href="http://sa2014.siggraph.org/en/">SIGGRAPH Asia 2014</a>&nbsp;(conference chair)</li>
	<li>SIGGRAPH Asia steering committee (2013-)</li>
	<li><a href="http://ieeevis.org/year/2016/info/committees/scivis-steering-committee">IEEE SciVIS Steering committee</a>&nbsp;(2014-)</li>
	<li><a href="http://vis.computer.org/">IEEE Visualization</a>&nbsp;<a href="http://vis.computer.org/vis2007/">2007</a>,&nbsp;<a href="http://vis.computer.org/vis2006/">2006</a>&nbsp;(general co-chair),&nbsp;<a href="http://vis.computer.org/vis2005/">2005</a>&nbsp;(general co-chair), and&nbsp;<a href="http://vis.computer.org/vis2004/">2004</a>&nbsp;(program co-chair)</li>
	<li><a href="http://mm.cse.wustl.edu/pg07/index.php">Pacific Graphics 2007</a></li>
	<li>Symposium on Point-based Graphics&nbsp;<a href="https://graphics.ethz.ch/events/pbg/07/">2007</a>&nbsp;(program co-chair),&nbsp;<a href="https://graphics.ethz.ch/events/pbg/06/">2006</a>&nbsp;(papers co-chair),&nbsp;<a href="http://www.cs.princeton.edu/gfx/pbg05/index.html">2005</a>,&nbsp;<a href="https://graphics.ethz.ch/events/pbg/">2004</a></li>
	<li><a href="http://pma.cirad.fr/PMA06/index.htm">PMA06:The Second International Symposium on Plant growth Modeling,Simulation, Visualization and Applications</a>&nbsp;2006 (also keynote speaker)</li>
	<li><a href="http://www.eurovis.org/">Eurographics/IEEE-VGTC Symposium on Visualization</a>&nbsp;<a href="http://dcgi.felk.cvut.cz/cgg/eg07/">2007</a>,&nbsp;<a href="https://www.cg.tuwien.ac.at/events/EG06/index.php">2006</a></li>
	<li>Eurographics Workshop on Sketch-Based Interfaces and Modeling (SBIM) 2007, 2006 (<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2006.00923.x">my report on SBIM'05</a>)</li>
	<li>International Conference on 3-D Digital Imaging and Modeling 2005</li>
	<li>Symposium on Volume Visualization and Graphics(VolVis) 2004, 2002</li>
	<li>Computer Graphics International 2005,&nbsp;<a href="http://www.ics.forth.gr/cgi2004/intro.html">2004</a></li>
	<li>IEEE Volume Graphics 2006, 2003, 2001</li>
</ul>

<p><span style="font-size: medium;">中文文章：</span></p>

<ul>
	<li>2015年第9期 <a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102171239805155.pdf">变革中的大学计算机学科建设</a>&nbsp;(<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102172141930206.pdf">Daniel Cohen-Or</a>, <a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102172147749317.pdf">James D. Foley</a>, <a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102172151926439.pdf">张晓东</a>)</li>
	<li>2015年第1期&nbsp;<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102171234435043.pdf">SIGGRAPH Asia 2014</a></li>
	<li>2012年第6期&nbsp;<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102171228278940.pdf">青年科技工作者的价值与成功</a></li>
</ul>

                </td>
    </tr>

    <tr>
      <td><i><font size="+2" color="#5F3F0E">Teaching</font></i></td>

      <td>
        <font size="+0">Classes taught (not up to date):</font>

        <ul>

                      <li><font size="+0">Computer Generated Imagery and Visual Effects, <a href="https://computergive.github.io/2018-fall/index.html">Fall 2018</a>, <a href="https://computergive.github.io/2019-spring/index.html">Spring 2019</a></font>
</li>
                      <li>Computer Graphics, Fall 2014, Fall 2015
</li>
                      <li><font size="+0">Algorithms and Data
          Structures</font></li>
                      <li><font size="+0">Commodity Graphics Hardware
          Accelerated Rendering</font></li>
                    
        </ul>
      </td>
    </tr>
  </tbody></table>

  <table align="center" width="1024" summary="">
    <tbody><tr>
      <td>
        <h2>Short Biography</h2>
      </td>
    </tr>
  
      <tr>
      <td>
                  <p><span style="color: rgb(0, 0, 0); font-family: &quot;lucida Grande&quot;, Verdana, &quot;Microsoft YaHei&quot;; font-size: medium;">陈宝权，北京大学博雅特聘教授，智能学院副院长。研究领域为计算机图形学、三维视觉与可视化，担任国家“973计划”“城市大数据计算理论与方法”项目首席科学家，主持国家自然科学基金重点项目、国家重点研发计划“科技冬奥”项目和新一代人工智能重大项目等。在 ACM SIGGRAPH、IEEE VIS、ACM Transactions on Graphics (TOG)、IEEE Transactions on Visualization and Computer Graphics （TVCG） 等国际会议和期刊发表论文200余篇，多次获得国际会议最佳论文奖，包括SIGGRAPH Asia 2022、SIGGRAPH 2022 （提名）和IEEE Visualization 2005等。现任中国图象图形学学会常务理事、三维视觉专委会主任；中国计算机学会（CCF）常务理事、《中国计算机学会通讯》专题主编；获美国国家科学基金会杰出青年学者奖（NSF CAREER Award 2003）、中国计算机图形学大会杰出奖（2014）。入选中科院百人计划（2008）、国家杰出青年科学基金资助（2010）、教育部长江学者特聘教授（2015）、国家万人计划领军人才（2017）。2017年当选中国计算机学会会士，2019年当选 IEEE Fellow，2021年入选IEEE Visualization Academy（可视化名人堂），当选中国图象图形学学会会士，2024年入选ACM SIGGRAPH Academy（计算机图形学名人堂）。</span></p>

              </td>
    </tr>
      <tr>
      <td>
                  <p>Baoquan Chen is a Professor of <a href="http://www.pku.edu.cn/">Peking University</a>, where he is the Associate Dean of <a href="https://www.cis.pku.edu.cn/">the School of Artificial Intelligence</a>. His research interests generally lie in computer graphics, computer vision, visualization, and human-computer interaction. He has published more than 200 papers in international journals and conferences, including 60+ papers in ACM Transactions on Graphics (TOG)/SIGGRAPH/SIGGRAPH_Asia. Chen serves/served as associate editor of IEEE Transactions on Emerging Topics in Computing (TETC), ACM Transactions On Graphics (TOG) and IEEE Transactions on Visualization and Computer Graphics (TVCG), and has served as chairs of prestigious conferences such as <a href="http://irc.cs.sdu.edu.cn/3dv/index.html">3D Vision 2017</a>, <a href="https://sa2014.siggraph.org/en/">SIGGRAPH Asia 2014</a>, <a href="http://vis.computer.org/vis2005/">IEEE Visualization 2005</a>. Chen is the recipient of 2002 Microsoft Innovation Excellence Program, 2003 <a href="http://www.nsf.gov/home/crssprgm/career/start.htm">NSF CAREER</a> award, 2004 McKnight Land-Grant Professorship at the University of Minnesota (Twin Cities), and 2014 Outstanding Achievement Award of Chinagraph. Chen received Best Paper Award in several prestigious conferences, such as <a href="https://sa2022.siggraph.org/en/index.html">SIGGRAPH Asia (2022)</a>, <a href="https://s2022.siggraph.org/">SIGGRAPH (2022 Honorary Mention)</a>, and <a href="http://vis.computer.org/vis2005/">IEEE Visualization (2005)</a>.</p>

<p>
  Prior to the current post, he was executive director of the <a href="https://cfcs.pku.edu.cn/english/">Center on Frontiers of Computing Studies</a>, Peking University (2018-2022); dean of the <a href="http://www.cs.en.qd.sdu.edu.cn/">School of Computer Science and Technology and the School of Software</a>, Shandong University (2013-2018). He was also founding director of the <a href="https://siat-vcc.github.io/">Visual Computing Research Center of Shenzhen Institute of Advanced Technology</a> (SIAT), Chinese Academy of Sciences (2008-2013), and a faculty member at the <a href="https://cse.umn.edu/cs">department of Computer Science and Engineering</a> at the University of Minnesota at Twin Cities (2000-2008). Chen received an MS in Electronic Engineering from Tsinghua University, and PhD in Computer Science from the State University of New York at Stony Brook. He is an IEEE Fellow, and was inducted to <a href="https://tc.computer.org/vgtc/awards/visualization-academy/">IEEE Visualization Academy</a> and <a href="https://www.siggraph.org/awards/acm-siggraph-academy/">ACM SIGGRAPH Academy</a> in 2021 and 2024, respectively.
</p>

<p>&nbsp;</p>

              </td>
    </tr>
  	
  </tbody></table>

  <p align="center"><img src="./figure/feather.gif" alt=""></p>
  
  <!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=10716942; 
var sc_invisible=1; 
var sc_security="0bb55d3c"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script><script type="text/javascript" src="./figure/counter.js.下载"></script></body></html>